{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Building Blocks of Neural Networks\n",
    "def assert_same_shape(array: ndarray, array_grad: ndarray):\n",
    "    assert array.shape == array_grad.shape, f\"array and grad shapes do not match:  {array.shape} != {array_grad.shape}\"\n",
    "\n",
    "a, b = np.array([1, 2, 3]), np.array([[1], [2]])\n",
    "# assert_same_shape(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations\n",
    "class Operation:\n",
    "    def forward(self, input_:ndarray):\n",
    "        self.input_ = input_\n",
    "        self.output = self._output()\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, output_grad: ndarray) -> ndarray:\n",
    "        assert_same_shape(self.output, output_grad)\n",
    "        self.input_grad = self._input_grad(output_grad)\n",
    "        assert_same_shape(self.input_, self.input_grad)\n",
    "        return self.input_grad\n",
    "\n",
    "    def _output(self) -> ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "class ParamOperation(Operation):\n",
    "    def __init__(self, param: ndarray):\n",
    "        self.param = param\n",
    "\n",
    "    def backward(self, output_grad: ndarray) -> ndarray:\n",
    "        super().backward(output_grad)\n",
    "        self.param_grad = self._param_grad(output_grad)\n",
    "        assert_same_shape(self.param, self.param_grad)\n",
    "        return self.input_grad\n",
    "\n",
    "    def _param_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        raise NotImplementedError\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers\n",
    "class WeightMultiply(ParamOperation):\n",
    "    def _output(self) -> ndarray:\n",
    "        return np.dot(self.input_, self.param)\n",
    "\n",
    "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        return np.dot(output_grad, np.transpose(self.param))\n",
    "\n",
    "    def _param_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        return np.dot(np.transpose(self.input_), output_grad)\n",
    "\n",
    "class BiasAdd(ParamOperation):\n",
    "    def __ini__(self, B: ndarray):\n",
    "        assert B.shape[0] == 1\n",
    "        super().__ini__(B)\n",
    "\n",
    "    def _output(self) -> ndarray:\n",
    "        return self.input_ + self.param\n",
    "\n",
    "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        return np.one_likes(self.input_) * output_grad\n",
    "\n",
    "    def _param_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        param_grad = np.one_likes(self.param) * output_grad\n",
    "        return np.sum(param_grad, axis=0).reshape(1, param_grad.shape[1])\n",
    "\n",
    "class Sigmoid(Operation):\n",
    "    def _output(self) -> ndarray:\n",
    "        return 1 / (1 + np.exp(-1 * self.input_))\n",
    "\n",
    "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        sigmoid_backward = self._output() * (1 - self._output())\n",
    "        return sigmoid_backward * output_grad\n",
    "\n",
    "class Linear(Operation):\n",
    "    def _output(self) -> ndarray:\n",
    "        return self.input_\n",
    "\n",
    "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        return output_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}