{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Softmax Cross Entropy Loss Function\n",
    "import numpy as np\n",
    "from lincoln import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 1,  0],\n",
       "       [ 2, -1]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "a = np.array([[0], [1], [2]])\n",
    "normalize(a) # ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "unnormalize(a) # ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load()\n",
    "# slice sets off to run faster with acceptable accuracy, down from 60000, 10000\n",
    "X_train = X_train[0:15000]\n",
    "y_train = y_train[0:15000]\n",
    "X_test = X_test[0:2500]\n",
    "y_test = y_test[0:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "num_labels = len(y_train)\n",
    "train_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    train_labels[i][y_train[i]] = 1\n",
    "\n",
    "num_labels = len(y_test)\n",
    "test_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    test_labels[i][y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train - np.mean(X_train), X_test - np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-33.79115382653061, 221.2088461734694, -33.79115382653061, 221.2088461734694)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / np.std(X_train), X_test / np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-0.4269135622397206,\n",
       " 2.794727194095053,\n",
       " -0.4269135622397206,\n",
       " 2.794727194095053)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_model(model, test_set):\n",
    "    return print(f'''The model validation accuracy is: {np.equal(np.argmax(model.forward(test_set, inference=True), axis=1), y_test).sum() * 100.0 / test_set.shape[0]:.2f}%''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.822\n",
      "Validation loss after 20 epochs is 0.741\n",
      "Validation loss after 30 epochs is 0.713\n",
      "Validation loss after 40 epochs is 0.696\n",
      "Validation loss after 50 epochs is 0.680\n",
      "The model validation accuracy is: 50.44%\n"
     ]
    }
   ],
   "source": [
    "# Mean squared error and sigmoid activation\n",
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh()), \n",
    "            Dense(neurons=10, activation=Sigmoid())],\n",
    "    loss = MeanSquaredError(normalize=False), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.943\n",
      "Loss increased after epoch 20, final loss was 0.943, using model from epoch 10\n",
      "The model validation accuracy is: 43.48%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh()),\n",
    "            Dense(neurons=10, activation=Sigmoid())],\n",
    "    loss = MeanSquaredError(normalize=True), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 1 epochs is 2.974\n",
      "Validation loss after 2 epochs is 2.262\n",
      "Validation loss after 3 epochs is 1.935\n",
      "Validation loss after 4 epochs is 1.757\n",
      "Validation loss after 5 epochs is 1.637\n",
      "Validation loss after 6 epochs is 1.550\n",
      "Validation loss after 7 epochs is 1.469\n",
      "Validation loss after 8 epochs is 1.417\n",
      "Validation loss after 9 epochs is 1.369\n",
      "Validation loss after 10 epochs is 1.355\n",
      "Validation loss after 11 epochs is 1.308\n",
      "Validation loss after 12 epochs is 1.284\n",
      "Validation loss after 13 epochs is 1.253\n",
      "Validation loss after 14 epochs is 1.236\n",
      "Validation loss after 15 epochs is 1.214\n",
      "Validation loss after 16 epochs is 1.198\n",
      "Validation loss after 17 epochs is 1.179\n",
      "Validation loss after 18 epochs is 1.167\n",
      "Validation loss after 19 epochs is 1.152\n",
      "Validation loss after 20 epochs is 1.143\n",
      "Validation loss after 21 epochs is 1.135\n",
      "Validation loss after 22 epochs is 1.132\n",
      "Validation loss after 23 epochs is 1.123\n",
      "Validation loss after 24 epochs is 1.114\n",
      "Validation loss after 25 epochs is 1.106\n",
      "Validation loss after 26 epochs is 1.094\n",
      "Loss increased after epoch 27, final loss was 1.094, using model from epoch 26\n",
      "The model validation accuracy is: 81.48%\n"
     ]
    }
   ],
   "source": [
    "# Softmax Cross Entropy Loss\n",
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Sigmoid()),\n",
    "            Dense(neurons=10, activation=Linear())],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 130, eval_every = 1, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 1 epochs is 1.208\n",
      "Validation loss after 2 epochs is 1.020\n",
      "Validation loss after 3 epochs is 0.912\n",
      "Validation loss after 4 epochs is 0.887\n",
      "Validation loss after 5 epochs is 0.860\n",
      "Loss increased after epoch 6, final loss was 0.860, using model from epoch 5\n",
      "The model validation accuracy is: 85.08%\n"
     ]
    }
   ],
   "source": [
    "# SGD Momentum\n",
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Sigmoid()),\n",
    "            Dense(neurons=10, activation=Linear())],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.1, momentum=0.9))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 1, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.994\n",
      "Loss increased after epoch 20, final loss was 0.994, using model from epoch 10\n",
      "The model validation accuracy is: 87.32%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh()),\n",
    "            Dense(neurons=10, activation=Linear())],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.1, momentum=0.9))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.877\n",
      "Validation loss after 20 epochs is 0.806\n",
      "Loss increased after epoch 30, final loss was 0.806, using model from epoch 20\n",
      "The model validation accuracy is: 90.04%\n"
     ]
    }
   ],
   "source": [
    "# Different weight decay\n",
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh()),\n",
    "            Dense(neurons=10, activation=Linear())],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(0.15, momentum=0.9, final_lr = 0.05, decay_type='linear')\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 1.163\n",
      "Validation loss after 20 epochs is 0.969\n",
      "Validation loss after 30 epochs is 0.863\n",
      "Loss increased after epoch 40, final loss was 0.863, using model from epoch 30\n",
      "The model validation accuracy is: 88.36%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh()),\n",
    "            Dense(neurons=10, activation=Linear())],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential')\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.705\n",
      "Validation loss after 20 epochs is 0.654\n",
      "Validation loss after 30 epochs is 0.605\n",
      "Loss increased after epoch 40, final loss was 0.605, using model from epoch 30\n",
      "The model validation accuracy is: 92.68%\n"
     ]
    }
   ],
   "source": [
    "# Weight Initialization\n",
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh(), weight_init=\"glorot\"),\n",
    "            Dense(neurons=10, activation=Linear(), weight_init=\"glorot\")],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(0.15, momentum=0.9, final_lr = 0.05, decay_type='linear')\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60, early_stopping=True)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.871\n",
      "Validation loss after 20 epochs is 0.844\n",
      "Validation loss after 30 epochs is 0.793\n",
      "Loss increased after epoch 40, final loss was 0.793, using model from epoch 30\n",
      "The model validation accuracy is: 90.76%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh(), weight_init=\"glorot\"),\n",
    "            Dense(neurons=10, activation=Linear(), weight_init=\"glorot\")],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60, early_stopping=True)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.866\n",
      "Validation loss after 20 epochs is 0.766\n",
      "Loss increased after epoch 30, final loss was 0.766, using model from epoch 20\n",
      "The model validation accuracy is: 90.52%\n"
     ]
    }
   ],
   "source": [
    "# Dropout\n",
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh(), weight_init=\"glorot\", dropout=0.8),\n",
    "            Dense(neurons=10, activation=Linear(), weight_init=\"glorot\")],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60, early_stopping=True)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.755\n",
      "Loss increased after epoch 20, final loss was 0.755, using model from epoch 10\n",
      "The model validation accuracy is: 90.88%\n"
     ]
    }
   ],
   "source": [
    "# Deep Learning, with and without Dropout\n",
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178, activation=Tanh(), weight_init=\"glorot\", dropout=0.8),\n",
    "            Dense(neurons=46, activation=Tanh(), weight_init=\"glorot\", dropout=0.8),\n",
    "            Dense(neurons=10, activation=Linear(), weight_init=\"glorot\")],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 100, eval_every = 10, seed=20190119, batch_size=60, early_stopping=True)\n",
    "calc_accuracy_model(model, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178, activation=Tanh(), weight_init=\"glorot\"),\n",
    "            Dense(neurons=46, activation=Tanh(), weight_init=\"glorot\"),\n",
    "            Dense(neurons=10, activation=Linear(), weight_init=\"glorot\")],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 100, eval_every = 10, seed=20190119, batch_size=60, early_stopping=True)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}