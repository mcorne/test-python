{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Softmax Cross Entropy Loss Function\n",
    "import numpy as np\n",
    "from lincoln import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0,  1],\n",
       "       [ 1,  0],\n",
       "       [ 2, -1]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "a = np.array([[0], [1], [2]])\n",
    "normalize(a) # ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0]])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "unnormalize(a) # ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load()\n",
    "# slice sets off to run faster with acceptable accuracy\n",
    "# X_train = X_train[0:12000]\n",
    "# y_train = y_train[0:12000]\n",
    "# X_test = X_test[0:2000]\n",
    "# y_test = y_test[0:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "num_labels = len(y_train)\n",
    "train_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    train_labels[i][y_train[i]] = 1\n",
    "\n",
    "num_labels = len(y_test)\n",
    "test_labels = np.zeros((num_labels, 10))\n",
    "for i in range(num_labels):\n",
    "    test_labels[i][y_test[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train - np.mean(X_train), X_test - np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-33.318421449829934,\n",
       " 221.68157855017006,\n",
       " -33.318421449829934,\n",
       " 221.68157855017006)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / np.std(X_train), X_test / np.std(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(-0.424073894391566, 2.821543345689335, -0.424073894391566, 2.821543345689335)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "np.min(X_train), np.max(X_train), np.min(X_test), np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_model(model, test_set):\n",
    "    return print(f'''The model validation accuracy is: {np.equal(np.argmax(model.forward(test_set, inference=True), axis=1), y_test).sum() * 100.0 / test_set.shape[0]:.2f}%''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.611\n",
      "Validation loss after 20 epochs is 0.426\n",
      "Validation loss after 30 epochs is 0.389\n",
      "Validation loss after 40 epochs is 0.374\n",
      "Validation loss after 50 epochs is 0.366\n",
      "The model validation accuracy is: 72.61%\n"
     ]
    }
   ],
   "source": [
    "# Mean squared error and sigmoid activation\n",
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh()), \n",
    "            Dense(neurons=10, activation=Sigmoid())],\n",
    "    loss = MeanSquaredError(normalize=False), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.952\n",
      "Loss increased after epoch 20, final loss was 0.952, using model from epoch 10\n",
      "The model validation accuracy is: 41.73%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh()),\n",
    "            Dense(neurons=10, activation=Sigmoid())],\n",
    "    loss = MeanSquaredError(normalize=True), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 1 epochs is 1.285\n",
      "Validation loss after 2 epochs is 0.970\n",
      "Validation loss after 3 epochs is 0.836\n",
      "Validation loss after 4 epochs is 0.763\n",
      "Validation loss after 5 epochs is 0.712\n",
      "Validation loss after 6 epochs is 0.679\n",
      "Validation loss after 7 epochs is 0.651\n",
      "Validation loss after 8 epochs is 0.631\n",
      "Validation loss after 9 epochs is 0.617\n",
      "Validation loss after 10 epochs is 0.599\n",
      "Validation loss after 11 epochs is 0.588\n",
      "Validation loss after 12 epochs is 0.576\n",
      "Validation loss after 13 epochs is 0.568\n",
      "Validation loss after 14 epochs is 0.557\n",
      "Validation loss after 15 epochs is 0.550\n",
      "Validation loss after 16 epochs is 0.544\n",
      "Validation loss after 17 epochs is 0.537\n",
      "Validation loss after 18 epochs is 0.533\n",
      "Validation loss after 19 epochs is 0.529\n",
      "Validation loss after 20 epochs is 0.523\n",
      "Validation loss after 21 epochs is 0.517\n",
      "Validation loss after 22 epochs is 0.512\n",
      "Validation loss after 23 epochs is 0.507\n",
      "Loss increased after epoch 24, final loss was 0.507, using model from epoch 23\n",
      "The model validation accuracy is: 91.04%\n"
     ]
    }
   ],
   "source": [
    "# Softmax Cross Entropy Loss\n",
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Sigmoid()),\n",
    "            Dense(neurons=10, activation=Linear())],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGD(0.1))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 130, eval_every = 1, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 1 epochs is 0.615\n",
      "Validation loss after 2 epochs is 0.489\n",
      "Validation loss after 3 epochs is 0.445\n",
      "Loss increased after epoch 4, final loss was 0.445, using model from epoch 3\n",
      "The model validation accuracy is: 91.96%\n"
     ]
    }
   ],
   "source": [
    "# SGD Momentum\n",
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Sigmoid()),\n",
    "            Dense(neurons=10, activation=Linear())],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.1, momentum=0.9))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 1, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.370\n",
      "Validation loss after 20 epochs is 0.334\n",
      "Validation loss after 30 epochs is 0.306\n",
      "Loss increased after epoch 40, final loss was 0.306, using model from epoch 30\n",
      "The model validation accuracy is: 95.20%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh()),\n",
    "            Dense(neurons=10, activation=Linear())],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "trainer = Trainer(model, SGDMomentum(0.1, momentum=0.9))\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.427\n",
      "Validation loss after 20 epochs is 0.393\n",
      "Validation loss after 30 epochs is 0.338\n",
      "Validation loss after 40 epochs is 0.295\n",
      "Loss increased after epoch 50, final loss was 0.295, using model from epoch 40\n",
      "The model validation accuracy is: 95.82%\n"
     ]
    }
   ],
   "source": [
    "# Different weight decay\n",
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh()),\n",
    "            Dense(neurons=10, activation=Linear())],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(0.15, momentum=0.9, final_lr = 0.05, decay_type='linear')\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation loss after 10 epochs is 0.530\n",
      "Validation loss after 20 epochs is 0.422\n",
      "Validation loss after 30 epochs is 0.364\n",
      "Validation loss after 40 epochs is 0.336\n",
      "Validation loss after 50 epochs is 0.326\n",
      "The model validation accuracy is: 95.40%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=89, activation=Tanh()),\n",
    "            Dense(neurons=10, activation=Linear())],\n",
    "    loss = SoftmaxCrossEntropy(), \n",
    "    seed=20190119)\n",
    "\n",
    "optimizer = SGDMomentum(0.2, momentum=0.9, final_lr = 0.05, decay_type='exponential')\n",
    "trainer = Trainer(model, optimizer)\n",
    "trainer.fit(X_train, train_labels, X_test, test_labels, epochs = 50, eval_every = 10, seed=20190119, batch_size=60)\n",
    "calc_accuracy_model(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}